{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyntcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.22.4\n",
      "Uninstalling numpy-1.22.4:\n",
      "  Successfully uninstalled numpy-1.22.4\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy==1.22.4\n",
      "  Using cached numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.22.4\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/ubuntu/.local/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.10/site-packages (4.66.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensordict-nightly in /home/ubuntu/.local/lib/python3.10/site-packages (2024.10.20)\n",
      "Requirement already satisfied: orjson in /home/ubuntu/.local/lib/python3.10/site-packages (from tensordict-nightly) (3.10.9)\n",
      "Requirement already satisfied: cloudpickle in /home/ubuntu/.local/lib/python3.10/site-packages (from tensordict-nightly) (3.1.0)\n",
      "Requirement already satisfied: torch>=2.5.0.dev in /usr/local/lib/python3.10/dist-packages (from tensordict-nightly) (2.5.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.10/site-packages (from tensordict-nightly) (1.22.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (2.21.5)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (10.3.5.147)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (3.1.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (3.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (11.2.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->tensordict-nightly) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.5.0.dev->tensordict-nightly) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.5.0.dev->tensordict-nightly) (3.0.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchrl-nightly in /home/ubuntu/.local/lib/python3.10/site-packages (2024.10.20)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.10/site-packages (from torchrl-nightly) (1.22.4)\n",
      "Requirement already satisfied: cloudpickle in /home/ubuntu/.local/lib/python3.10/site-packages (from torchrl-nightly) (3.1.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from torchrl-nightly) (21.3)\n",
      "Requirement already satisfied: tensordict-nightly in /home/ubuntu/.local/lib/python3.10/site-packages (from torchrl-nightly) (2024.10.20)\n",
      "Requirement already satisfied: torch>=2.5.0.dev in /usr/local/lib/python3.10/dist-packages (from torchrl-nightly) (2.5.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (12.4.5.8)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (10.3.5.147)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (4.12.2)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (12.4.127)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (3.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (12.4.127)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0.dev->torchrl-nightly) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.5.0.dev->torchrl-nightly) (1.3.0)\n",
      "Requirement already satisfied: orjson in /home/ubuntu/.local/lib/python3.10/site-packages (from tensordict-nightly->torchrl-nightly) (3.10.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.5.0.dev->torchrl-nightly) (3.0.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: torch==2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.10/site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (12.3.1.170)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.4.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (2.21.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.0->torchvision) (3.0.2)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.20.0\n"
     ]
    }
   ],
   "source": [
    "# first time installs\n",
    "!pip uninstall numpy -y\n",
    "!pip install numpy==1.22.4\n",
    "!pip install pandas\n",
    "!pip install tqdm\n",
    "!pip install tensordict-nightly\n",
    "!pip install torchrl-nightly\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /usr/local/cuda/lib64 | grep libcudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torchrl/data/replay_buffers/samplers.py:37: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. If you installed TorchRL from PyPI, please report the bug on TorchRL github. If you installed TorchRL locally and/or in development mode, check that you have all the required compiling packages.\n",
      "  warnings.warn(EXTENSION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "from tensordict import TensorDict, TensorDictBase\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec\n",
    "from torchrl.envs import (\n",
    "    EnvBase,\n",
    "    Transform,\n",
    "    Compose,\n",
    "    ToTensorImage,\n",
    "    Resize,\n",
    "    TransformedEnv,\n",
    "    UnsqueezeTransform,\n",
    ")\n",
    "\n",
    "\n",
    "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
    "from torchrl.envs.utils import check_env_specs, step_mdp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment\n",
    "#### `_step()`\n",
    "\n",
    "- Read the input keys (such as \"action\") and execute the simulation based on these;\n",
    "- Retrieve observations, done state and reward;\n",
    "- Write the set of observation values along with the reward and done state at the corresponding entries in a new TensorDict.\n",
    "- Merge the output TensorDict (as \"next\" key) in the input TensorDict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "data_path = '/ROS2_my_bot/my_bot/src/my_bot_controller/resource/24_10_19_sensorDump/'\n",
    "image_path = 'egoCam/*.png'\n",
    "\n",
    "image_files = glob.glob(data_path + image_path)\n",
    "trajectory_data = pd.read_csv(data_path + 'trajectory.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _step(tensordict):\n",
    "    \n",
    "    # take a step\n",
    "    step = tensordict[\"stepInt\"].item()\n",
    "\n",
    "    image = cv.imread(image_files[step])\n",
    "    image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "    step += 1\n",
    "\n",
    "    step_tensor = torch.tensor(step, dtype=torch.int32)\n",
    "\n",
    "    # laser_readings = \"\"\n",
    "    # laser_tensor = torch.tensor(laser_readings, dtype=torch.float32)\n",
    "\n",
    "    progress = torch.tensor(0, dtype=torch.float32)\n",
    "\n",
    "    reward = progress.view(*tensordict.shape, 1)\n",
    "    done = torch.zeros_like(reward, dtype=torch.bool)\n",
    "\n",
    "\n",
    "    # write observations\n",
    "    # merge the output with input tensordict\n",
    "    out = TensorDict(\n",
    "        {\n",
    "            \"stepInt\": step_tensor,\n",
    "            \"image\": image_tensor,\n",
    "            # \"laser\": laser_tensor,\n",
    "            \"params\": tensordict[\"params\"],\n",
    "            \"reward\": reward,\n",
    "            \"done\": done,\n",
    "        },\n",
    "        tensordict.shape,\n",
    "    )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# retrieve observations (observations, reward, done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reset(self, tensordict):\n",
    "    if tensordict is None or tensordict.is_empty():\n",
    "        # if no ``tensordict`` is passed, we generate a single set of hyperparameters\n",
    "        # Otherwise, we assume that the input ``tensordict`` contains all the relevant\n",
    "        # parameters to get started.\n",
    "        tensordict = self.gen_params(batch_size=self.batch_size)\n",
    "\n",
    "\n",
    "    # retrieve observations (observations, reward, done)\n",
    "    step = 0\n",
    "\n",
    "    step_tensor = torch.tensor(step, dtype=torch.int32)\n",
    "    # take a step\n",
    "    image = cv.imread(image_files[step])\n",
    "    image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "    out = TensorDict(\n",
    "        {   \n",
    "            \"stepInt\": step_tensor,\n",
    "            \"image\": image_tensor,\n",
    "            \"params\": tensordict[\"params\"],\n",
    "        },\n",
    "        batch_size=tensordict.shape,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment metadata: `env.*_spec`\n",
    "\n",
    "The specs define the input and output domain of the environment. They can also be used to instantiate lazily defined neural networks and test scripts. There are four specs that we must code in our environment:\n",
    "\n",
    "- `EnvBase.observation_spec`: This will be a `CompositeSpec` instance where each key is an observation (a CompositeSpec can be viewed as a dictionary of specs).\n",
    "- `EnvBase.action_spec`: It can be any type of spec, it corresponds to the \"action\" entry in the input tensordict;\n",
    "- `EnvBase.reward_spec`: provides information about the reward space;\n",
    "- `EnvBase.done_spec`: provides information about the space of the done flag.\n",
    "\n",
    "TorchRL specs are organized in two general containers:\n",
    "- input_spec which contains the specs of the information that the step function reads (divided between action_spec containing the action and state_spec containing all the rest),\n",
    "- output_spec which encodes the specs that the step outputs (observation_spec, reward_spec and done_spec).\n",
    "\n",
    "In general, you should not interact directly with output_spec and input_spec but only with their content: observation_spec, reward_spec, done_spec, action_spec and state_spec. TorchRL offers multiple TensorSpec subclasses to encode the environment’s input and output characteristics.\n",
    "\n",
    "##### Specs shape\n",
    "The environment specs leading dimensions must match the environment batch-size. This is done to enforce that every component of an environment (including its transforms) have an accurate representation of the expected input and output shapes. This is something that should be accurately coded in stateful settings. For non batch-locked environments, such as the one in our example (see below), this is irrelevant as the environment batch size will most likely be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_spec(self, td_params):\n",
    "    # Under the hood, this will populate self.output_spec[\"observation\"]\n",
    "    self.observation_spec = CompositeSpec(\n",
    "        stepInt=BoundedTensorSpec(\n",
    "            low=td_params[\"params\", \"step_start\"],\n",
    "            high=td_params[\"params\", \"step_end\"],\n",
    "            shape=(),\n",
    "            dtype=torch.int32,\n",
    "        ),\n",
    "        image=UnboundedContinuousTensorSpec(\n",
    "            shape=(td_params[\"params\", \"imageHeight\"], td_params[\"params\", \"imageWidth\"], 3),\n",
    "            dtype=torch.float32,\n",
    "        ),\n",
    "        # we need to add the ``params`` to the observation specs, as we want\n",
    "        # to pass it at each step during a rollout\n",
    "        params=make_composite_from_td(td_params[\"params\"]),\n",
    "        shape=(),\n",
    "    )\n",
    "\n",
    "    # action-spec will be automatically wrapped in input_spec when\n",
    "    # `self.action_spec = spec` will be called supported\n",
    "    self.action_spec = CompositeSpec(\n",
    "        action=CompositeSpec(\n",
    "            linear_velocity=BoundedTensorSpec(\n",
    "                low=-td_params[\"params\", \"max_linear_velocity\"],\n",
    "                high=td_params[\"params\", \"max_linear_velocity\"],\n",
    "                shape=(),\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "            angular_velocity=BoundedTensorSpec(\n",
    "                low=-td_params[\"params\", \"max_angular_velocity\"],\n",
    "                high=td_params[\"params\", \"max_angular_velocity\"],\n",
    "                shape=(),\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "            shape=(),\n",
    "        ),\n",
    "        shape=(),\n",
    "    )\n",
    "    self.reward_spec = UnboundedContinuousTensorSpec(shape=(*td_params.shape, 1))\n",
    "\n",
    "\n",
    "def make_composite_from_td(td):\n",
    "    # custom function to convert a ``tensordict`` in a similar spec structure\n",
    "    # of unbounded values.\n",
    "    composite = CompositeSpec(\n",
    "        {\n",
    "            key: make_composite_from_td(tensor)\n",
    "            if isinstance(tensor, TensorDictBase)\n",
    "            else UnboundedContinuousTensorSpec(\n",
    "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
    "            )\n",
    "            for key, tensor in td.items()\n",
    "        },\n",
    "        shape=td.shape,\n",
    "    )\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_seed(self, seed: Optional[int]):\n",
    "    rng = torch.manual_seed(seed)\n",
    "    self.rng = rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_params(batch_size=None) -> TensorDictBase:\n",
    "    \"\"\"Returns a ``tensordict`` containing the physical parameters such as gravitational force and torque or speed limits.\"\"\"\n",
    "    if batch_size is None:\n",
    "        batch_size = []\n",
    "    td = TensorDict(\n",
    "        {\n",
    "            \"params\": TensorDict(\n",
    "                {\n",
    "                    \"step_start\": 0,\n",
    "                    \"step_end\": 20,\n",
    "                    \"max_linear_velocity\": 1.0,\n",
    "                    \"max_angular_velocity\": 1.0,\n",
    "                    \"imageHeight\": 480,\n",
    "                    \"imageWidth\": 640,\n",
    "                },\n",
    "                [],\n",
    "            )\n",
    "        },\n",
    "        [],\n",
    "    )\n",
    "    if batch_size:\n",
    "        td = td.expand(batch_size).contiguous()\n",
    "    return td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_botEnv(EnvBase):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 30,\n",
    "    }\n",
    "    batch_locked = True\n",
    "\n",
    "    def __init__(self, td_params=None, seed=None, device=\"cpu\"):\n",
    "        if td_params is None:\n",
    "            td_params = self.gen_params()\n",
    "\n",
    "        super().__init__(device=device, batch_size=[])\n",
    "        self._make_spec(td_params)\n",
    "        if seed is None:\n",
    "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
    "        self.set_seed(seed)\n",
    "\n",
    "    # Helpers: _make_step and gen_params\n",
    "    gen_params = staticmethod(gen_params)\n",
    "    _make_spec = _make_spec\n",
    "\n",
    "    # Mandatory methods: _step, _reset and _set_seed\n",
    "    _reset = _reset\n",
    "    _step = staticmethod(_step)\n",
    "    _set_seed = _set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check environment implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torchrl/data/tensor_specs.py:5464: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.7. Please use Bounded instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torchrl/data/tensor_specs.py:5464: DeprecationWarning: The UnboundedContinuousTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torchrl/data/tensor_specs.py:5464: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.7. Please use Composite instead.\n",
      "  warnings.warn(\n",
      "2024-10-20 21:48:00,865 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "env = my_botEnv()\n",
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_spec: Composite(\n",
      "    stepInt: BoundedDiscrete(\n",
      "        shape=torch.Size([]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.int32,\n",
      "        domain=discrete),\n",
      "    image: UnboundedContinuous(\n",
      "        shape=torch.Size([480, 640, 3]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([480, 640, 3]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([480, 640, 3]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    params: Composite(\n",
      "        step_start: UnboundedDiscrete(\n",
      "            shape=torch.Size([]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        step_end: UnboundedDiscrete(\n",
      "            shape=torch.Size([]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        max_linear_velocity: UnboundedContinuous(\n",
      "            shape=torch.Size([]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        max_angular_velocity: UnboundedContinuous(\n",
      "            shape=torch.Size([]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        imageHeight: UnboundedDiscrete(\n",
      "            shape=torch.Size([]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        imageWidth: UnboundedDiscrete(\n",
      "            shape=torch.Size([]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([])),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([]))\n",
      "state_spec: Composite(\n",
      ",\n",
      "    device=cpu,\n",
      "    shape=torch.Size([]))\n",
      "reward_spec: UnboundedContinuous(\n",
      "    shape=torch.Size([1]),\n",
      "    space=ContinuousBox(\n",
      "        low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "        high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "    device=cpu,\n",
      "    dtype=torch.float32,\n",
      "    domain=continuous)\n"
     ]
    }
   ],
   "source": [
    "print(\"observation_spec:\", env.observation_spec)\n",
    "print(\"state_spec:\", env.state_spec)\n",
    "print(\"reward_spec:\", env.reward_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset tensordict TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        image: Tensor(shape=torch.Size([480, 640, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                imageHeight: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                imageWidth: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                max_angular_velocity: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_linear_velocity: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                step_end: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                step_start: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        stepInt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.reset()\n",
    "print(\"reset tensordict\", td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random step tensordict TensorDict(\n",
      "    fields={\n",
      "        action: TensorDict(\n",
      "            fields={\n",
      "                angular_velocity: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                linear_velocity: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        image: Tensor(shape=torch.Size([480, 640, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                image: Tensor(shape=torch.Size([480, 640, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        imageHeight: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        imageWidth: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        max_angular_velocity: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_linear_velocity: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        step_end: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        step_start: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                stepInt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                imageHeight: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                imageWidth: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                max_angular_velocity: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_linear_velocity: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                step_end: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                step_start: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        stepInt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.rand_step(td)\n",
    "print(\"random step tensordict\", td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_env = my_botEnv()\n",
    "transform = Compose(ToTensorImage(in_keys=[\"image\"]), Resize(64, 64, in_keys=[\"image\"]))\n",
    "env = TransformedEnv(base_env, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 21:48:22,755 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data from rollout: TensorDict(\n",
      "    fields={\n",
      "        action: TensorDict(\n",
      "            fields={\n",
      "                action: TensorDict(\n",
      "                    fields={\n",
      "                        angular_velocity: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        linear_velocity: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([15]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False)},\n",
      "            batch_size=torch.Size([15]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        image: Tensor(shape=torch.Size([15, 3, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                image: Tensor(shape=torch.Size([15, 3, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        imageHeight: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        imageWidth: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        max_angular_velocity: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_linear_velocity: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        step_end: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        step_start: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "                    batch_size=torch.Size([15]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                stepInt: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([15]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                imageHeight: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                imageWidth: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                max_angular_velocity: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_linear_velocity: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                step_end: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                step_start: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([15]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        stepInt: Tensor(shape=torch.Size([15]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([15]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "def simple_rollout(steps=15):\n",
    "    # preallocate:\n",
    "    data = TensorDict({}, [steps])\n",
    "    # reset\n",
    "    _data = env.reset()\n",
    "    for i in range(steps):\n",
    "        _data[\"action\"] = env.action_spec.rand()\n",
    "        _data = env.step(_data)\n",
    "        data[i] = _data\n",
    "        _data = step_mdp(_data, keep_other=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "print(\"data from rollout:\", simple_rollout(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected a tensordict with shape==env.batch_size, got torch.Size([1]) and torch.Size([])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# number of environments to be executed in batch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m td \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreset (batch size of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, td)\n\u001b[1;32m      4\u001b[0m td \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrand_step(td)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchrl/envs/common.py:2163\u001b[0m, in \u001b[0;36mEnvBase.reset\u001b[0;34m(self, tensordict, **kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m \u001b[38;5;124;03m\"\"\"Resets the environment.\u001b[39;00m\n\u001b[1;32m   2149\u001b[0m \n\u001b[1;32m   2150\u001b[0m \u001b[38;5;124;03mAs for step and _step, only the private method :obj:`_reset` should be overwritten by EnvBase subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2160\u001b[0m \n\u001b[1;32m   2161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2163\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_tensordict_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2165\u001b[0m tensordict_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset(tensordict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2166\u001b[0m \u001b[38;5;66;03m# We assume that this is done properly\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m \u001b[38;5;66;03m# if reset.device != self.device:\u001b[39;00m\n\u001b[1;32m   2168\u001b[0m \u001b[38;5;66;03m#     reset = reset.to(self.device, non_blocking=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchrl/envs/common.py:2271\u001b[0m, in \u001b[0;36mEnvBase._assert_tensordict_shape\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_tensordict_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensordict: TensorDictBase) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2269\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_locked \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m!=\u001b[39m ()\n\u001b[1;32m   2270\u001b[0m     ) \u001b[38;5;129;01mand\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:\n\u001b[0;32m-> 2271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2272\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a tensordict with shape==env.batch_size, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2273\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensordict\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2274\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected a tensordict with shape==env.batch_size, got torch.Size([1]) and torch.Size([])"
     ]
    }
   ],
   "source": [
    "batch_size = 1 # number of environments to be executed in batch\n",
    "td = env.reset(env.gen_params(batch_size=[batch_size]))\n",
    "print(f\"reset (batch size of {batch_size})\", td)\n",
    "td = env.rand_step(td)\n",
    "print(f\"rand step (batch size of {batch_size})\", td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Simple Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "env.set_seed(0)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(1),\n",
    ")\n",
    "policy = TensorDictModule(\n",
    "    net,\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action\"],\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam(policy.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop\n",
    "We will successively:\n",
    "\n",
    "- generate a trajectory\n",
    "- sum the rewards\n",
    "- backpropagate through the graph defined by these operations\n",
    "- clip the gradient norm and make an optimization step\n",
    "- repeat\n",
    "\n",
    "At the end of the training loop, we should have a final reward close to 0 which demonstrates that the pendulum is upward and still as desired.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected a tensordict with shape==env.batch_size, got torch.Size([1]) and torch.Size([])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m logs \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m----> 7\u001b[0m     init_td \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrollout(\u001b[38;5;241m100\u001b[39m, policy, tensordict\u001b[38;5;241m=\u001b[39minit_td, auto_reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m     traj_return \u001b[38;5;241m=\u001b[39m rollout[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchrl/envs/common.py:2163\u001b[0m, in \u001b[0;36mEnvBase.reset\u001b[0;34m(self, tensordict, **kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m \u001b[38;5;124;03m\"\"\"Resets the environment.\u001b[39;00m\n\u001b[1;32m   2149\u001b[0m \n\u001b[1;32m   2150\u001b[0m \u001b[38;5;124;03mAs for step and _step, only the private method :obj:`_reset` should be overwritten by EnvBase subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2160\u001b[0m \n\u001b[1;32m   2161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2163\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_tensordict_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2165\u001b[0m tensordict_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset(tensordict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2166\u001b[0m \u001b[38;5;66;03m# We assume that this is done properly\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m \u001b[38;5;66;03m# if reset.device != self.device:\u001b[39;00m\n\u001b[1;32m   2168\u001b[0m \u001b[38;5;66;03m#     reset = reset.to(self.device, non_blocking=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchrl/envs/common.py:2271\u001b[0m, in \u001b[0;36mEnvBase._assert_tensordict_shape\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_tensordict_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensordict: TensorDictBase) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2269\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_locked \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m!=\u001b[39m ()\n\u001b[1;32m   2270\u001b[0m     ) \u001b[38;5;129;01mand\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:\n\u001b[0;32m-> 2271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2272\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a tensordict with shape==env.batch_size, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2273\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensordict\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2274\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected a tensordict with shape==env.batch_size, got torch.Size([1]) and torch.Size([])"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "pbar = tqdm.tqdm(range(20_000 // batch_size))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, 20_000)\n",
    "logs = defaultdict(list)\n",
    "\n",
    "for _ in pbar:\n",
    "    init_td = env.reset(env.gen_params(batch_size=[batch_size]))\n",
    "    rollout = env.rollout(100, policy, tensordict=init_td, auto_reset=False)\n",
    "    traj_return = rollout[\"next\", \"reward\"].mean()\n",
    "    (-traj_return).backward()\n",
    "    gn = torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    pbar.set_description(\n",
    "        f\"reward: {traj_return: 4.4f}, \"\n",
    "        f\"last reward: {rollout[..., -1]['next', 'reward'].mean(): 4.4f}, gradient norm: {gn: 4.4}\"\n",
    "    )\n",
    "    logs[\"return\"].append(traj_return.item())\n",
    "    logs[\"last_reward\"].append(rollout[..., -1][\"next\", \"reward\"].mean().item())\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "def plot():\n",
    "    import matplotlib\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    is_ipython = \"inline\" in matplotlib.get_backend()\n",
    "    if is_ipython:\n",
    "        from IPython import display\n",
    "\n",
    "    with plt.ion():\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(logs[\"return\"])\n",
    "        plt.title(\"returns\")\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(logs[\"last_reward\"])\n",
    "        plt.title(\"last reward\")\n",
    "        plt.xlabel(\"iteration\")\n",
    "        if is_ipython:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
